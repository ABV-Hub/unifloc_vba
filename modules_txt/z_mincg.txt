''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Copyright (c) 2010, Sergey Bochkanov (ALGLIB project).
'
'>>> SOURCE LICENSE >>>
'This program is free software; you can redistribute it and/or modify
'it under the terms of the GNU General Public License as published by
'the Free Software Foundation (www.fsf.org); either version 2 of the
'License, or (at your option) any later version.
'
'This program is distributed in the hope that it will be useful,
'but WITHOUT ANY WARRANTY; without even the implied warranty of
'MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
'GNU General Public License for more details.
'
'A copy of the GNU General Public License is available at
'http://www.fsf.org/licensing/licenses
'
'>>> END OF LICENSE >>>
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Data types
Public Type MinCGState
    N As Long
    EpsG As Double
    EpsF As Double
    EpsX As Double
    MaxIts As Long
    StpMax As Double
    XRep As Boolean
    CGType As Long
    NFEV As Long
    MCStage As Long
    K As Long
    XK() As Double
    DK() As Double
    XN() As Double
    DN() As Double
    D() As Double
    Fold As Double
    Stp As Double
    WORK() As Double
    YK() As Double
    X() As Double
    F As Double
    G() As Double
    NeedFG As Boolean
    XUpdated As Boolean
    RState As RCommState
    RepIterationsCount As Long
    RepNFEV As Long
    RepTerminationType As Long
    DebugRestartsCount As Long
    LState As LINMINState
    BetaHS As Double
    BetaDY As Double
End Type
Public Type MinCGReport
    IterationsCount As Long
    NFEV As Long
    TerminationType As Long
End Type
'Routines
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'        NONLINEAR CONJUGATE GRADIENT METHOD
'
'The subroutine minimizes function F(x) of N arguments by using one of  the
'nonlinear conjugate gradient methods.
'
'These CG methods are globally convergent (even on non-convex functions) as
'long as grad(f) is Lipschitz continuous in  a  some  neighborhood  of  the
'L = { x : f(x)<=f(x0) }.
'
'INPUT PARAMETERS:
'    N       -   problem dimension. N>0
'    X       -   initial solution approximation, array[0..N-1].
'    EpsG    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if the condition ||G|| < EpsG  is
'                satisfied, where ||.|| means Euclidian norm, G - gradient, X -
'                current approximation.
'    EpsF    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if on iteration  number  k+1  the
'                condition |F(k+1)-F(k)| <= EpsF*max{|F(k)|, |F(k+1)|, 1}    is
'                satisfied.
'    EpsX    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if on iteration number k+1    the
'                condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the number of
'                iterations is unlimited.
'
'OUTPUT PARAMETERS:
'    State - structure used for reverse communication.
'
'See also MinCGIteration, MinCGResults
'
'NOTE:
'
'Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
'automatic stopping criterion selection (small EpsX).
'
'  -- ALGLIB --
'     Copyright 25.03.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGCreate(ByVal N As Long, _
         ByRef X() As Double, _
         ByRef State As MinCGState)
    Dim i_ As Long
    
    '
    ' Initialize
    '
    State.N = N
    Call MinCGSetCond(State, 0#, 0#, 0#, 0#)
    Call MinCGSetXRep(State, False)
    Call MinCGSetStpMax(State, 0#)
    Call MinCGSetCGType(State, -1#)
    ReDim State.XK(0 To N - 1)
    ReDim State.DK(0 To N - 1)
    ReDim State.XN(0 To N - 1)
    ReDim State.DN(0 To N - 1)
    ReDim State.X(0 To N - 1)
    ReDim State.D(0 To N - 1)
    ReDim State.G(0 To N - 1)
    ReDim State.WORK(0 To N - 1)
    ReDim State.YK(0 To N - 1)
    
    '
    ' Prepare first run
    '
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = X(i_)
    Next i_
    ReDim State.RState.IA(0# To 2#)
    ReDim State.RState.RA(0# To 2#)
    State.RState.Stage = -1#
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets stopping conditions for CG optimization algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinCGCreate()
'    EpsG    -   >=0
'                The  subroutine  finishes  its  work   if   the  condition
'                ||G||<EpsG is satisfied, where ||.|| means Euclidian norm,
'                G - gradient.
'    EpsF    -   >=0
'                The  subroutine  finishes  its work if on k+1-th iteration
'                the  condition  |F(k+1)-F(k)|<=EpsF*max{|F(k)|,|F(k+1)|,1}
'                is satisfied.
'    EpsX    -   >=0
'                The subroutine finishes its work if  on  k+1-th  iteration
'                the condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
'                iterations is unlimited.
'
'Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
'automatic stopping criterion selection (small EpsX).
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetCond(ByRef State As MinCGState, _
         ByVal EpsG As Double, _
         ByVal EpsF As Double, _
         ByVal EpsX As Double, _
         ByVal MaxIts As Long)
    If EpsG = 0# And EpsF = 0# And EpsX = 0# And MaxIts = 0# Then
        EpsX = 0.000001
    End If
    State.EpsG = EpsG
    State.EpsF = EpsF
    State.EpsX = EpsX
    State.MaxIts = MaxIts
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function turns on/off reporting.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate()
'    NeedXRep-   whether iteration reports are needed or not
'
'Usually  algorithm  returns  from  MinCGIteration()  only  when  it  needs
'function/gradient. However, with this function we can let  it  stop  after
'each  iteration  (one  iteration  may  include   more  than  one  function
'evaluation), which is indicated by XUpdated field.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetXRep(ByRef State As MinCGState, ByVal NeedXRep As Boolean)
    State.XRep = NeedXRep
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets CG algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate()
'    CGType  -   algorithm type:
'                * -1    automatic selection of the best algorithm
'                * 0     DY (Dai and Yuan) algorithm
'                * 1     Hybrid DY-HS algorithm
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetCGType(ByRef State As MinCGState, ByVal CGType As Long)
    If CGType = -1# Then
        CGType = 1#
    End If
    State.CGType = CGType
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets maximum step length
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate()
'    StpMax  -   maximum step length, >=0. Set StpMax to 0.0,  if you don't
'                want to limit step length.
'
'Use this subroutine when you optimize target function which contains exp()
'or  other  fast  growing  functions,  and optimization algorithm makes too
'large  steps  which  leads  to overflow. This function allows us to reject
'steps  that  are  too  large  (and  therefore  expose  us  to the possible
'overflow) without actually calculating function value at the x+stp*d.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetStpMax(ByRef State As MinCGState, ByVal StpMax As Double)
    State.StpMax = StpMax
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'One conjugate gradient iteration
'
'Called after initialization with MinCG.
'See HTML documentation for examples.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinCG.
'
'RESULT:
'* if function returned False, iterative proces has converged.
'  Use MinLBFGSResults() to obtain optimization results.
'* if subroutine returned True, then, depending on structure fields, we
'  have one of the following situations
'
'
'=== FUNC/GRAD REQUEST ===
'State.NeedFG is True => function value/gradient are needed.
'Caller should calculate function value State.F and gradient
'State.G[0..N-1] at State.X[0..N-1] and call MinLBFGSIteration() again.
'
'=== NEW INTERATION IS REPORTED ===
'State.XUpdated is True => one more iteration was made.
'State.X contains current position, State.F contains function value at X.
'You can read info from these fields, but never modify  them  because  they
'contain the only copy of optimization algorithm state.
'
'One and only one of these fields (NeedFG, XUpdated) is true on return. New
'iterations are reported only when reports  are  explicitly  turned  on  by
'MinLBFGSSetXRep() function, so if you never called it, you can expect that
'NeedFG is always True.
'
'
'  -- ALGLIB --
'     Copyright 20.04.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Function MinCGIteration(ByRef State As MinCGState) As Boolean
    Dim Result As Boolean
    Dim N As Long
    Dim i As Long
    Dim BetaK As Double
    Dim V As Double
    Dim VV As Double
    Dim MCINFO As Long
    Dim i_ As Long
    
    '
    ' Reverse communication preparations
    ' I know it looks ugly, but it works the same way
    ' anywhere from C++ to Python.
    '
    ' This code initializes locals by:
    ' * random values determined during code
    '   generation - on first subroutine call
    ' * values from previous call - on subsequent calls
    '
    If State.RState.Stage >= 0# Then
        N = State.RState.IA(0#)
        i = State.RState.IA(1#)
        MCINFO = State.RState.IA(2#)
        BetaK = State.RState.RA(0#)
        V = State.RState.RA(1#)
        VV = State.RState.RA(2#)
    Else
        N = -983#
        i = -989#
        MCINFO = -834#
        BetaK = 900#
        V = -287#
        VV = 364#
    End If
    If State.RState.Stage = 0# Then
        GoTo lbl_0
    End If
    If State.RState.Stage = 1# Then
        GoTo lbl_1
    End If
    If State.RState.Stage = 2# Then
        GoTo lbl_2
    End If
    If State.RState.Stage = 3# Then
        GoTo lbl_3
    End If
    
    '
    ' Routine body
    '
    
    '
    ' Prepare
    '
    N = State.N
    State.RepTerminationType = 0#
    State.RepIterationsCount = 0#
    State.RepNFEV = 0#
    State.DebugRestartsCount = 0#
    
    '
    ' Calculate F/G, initialize algorithm
    '
    Call ClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 0#
    GoTo lbl_rcomm
lbl_0:
    If Not State.XRep Then
        GoTo lbl_4
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 1#
    GoTo lbl_rcomm
lbl_1:
lbl_4:
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.G(i_) * State.G(i_)
    Next i_
    V = Sqr(V)
    If V = 0# Then
        State.RepTerminationType = 4#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    State.RepNFEV = 1#
    State.K = 0#
    State.Fold = State.F
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.X(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DK(i_) = -State.G(i_)
    Next i_
    
    '
    ' Main cycle
    '
lbl_6:
    If False Then
        GoTo lbl_7
    End If
    
    '
    ' Store G[k] for later calculation of Y[k]
    '
    For i_ = 0# To N - 1# Step 1
        State.YK(i_) = -State.G(i_)
    Next i_
    
    '
    ' Calculate X(k+1): minimize F(x+alpha*d)
    '
    For i_ = 0# To N - 1# Step 1
        State.D(i_) = State.DK(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.XK(i_)
    Next i_
    State.MCStage = 0#
    State.Stp = 1#
    Call LinMinNormalizeD(State.D, State.Stp, N)
    Call MCSRCH(N, State.X, State.F, State.G, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
lbl_8:
    If State.MCStage = 0# Then
        GoTo lbl_9
    End If
    Call ClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 2#
    GoTo lbl_rcomm
lbl_2:
    Call MCSRCH(N, State.X, State.F, State.G, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
    GoTo lbl_8
lbl_9:
    If Not State.XRep Then
        GoTo lbl_10
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 3#
    GoTo lbl_rcomm
lbl_3:
lbl_10:
    For i_ = 0# To N - 1# Step 1
        State.XN(i_) = State.X(i_)
    Next i_
    If MCINFO = 1# Then
        
        '
        ' Standard Wolfe conditions hold
        ' Calculate Y[K] and BetaK
        '
        For i_ = 0# To N - 1# Step 1
            State.YK(i_) = State.YK(i_) + State.G(i_)
        Next i_
        VV = 0#
        For i_ = 0# To N - 1# Step 1
            VV = VV + State.YK(i_) * State.DK(i_)
        Next i_
        V = 0#
        For i_ = 0# To N - 1# Step 1
            V = V + State.G(i_) * State.G(i_)
        Next i_
        State.BetaDY = V / VV
        V = 0#
        For i_ = 0# To N - 1# Step 1
            V = V + State.G(i_) * State.YK(i_)
        Next i_
        State.BetaHS = V / VV
        If State.CGType = 0# Then
            BetaK = State.BetaDY
        End If
        If State.CGType = 1# Then
            BetaK = MaxReal(0#, MinReal(State.BetaDY, State.BetaHS))
        End If
    Else
        
        '
        ' Something is wrong (may be function is too wild or too flat).
        '
        ' We'll set BetaK=0, which will restart CG algorithm.
        ' We can stop later (during normal checks) if stopping conditions are met.
        '
        BetaK = 0#
        State.DebugRestartsCount = State.DebugRestartsCount + 1#
    End If
    
    '
    ' Calculate D(k+1)
    '
    For i_ = 0# To N - 1# Step 1
        State.DN(i_) = -State.G(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DN(i_) = State.DN(i_) + BetaK * State.DK(i_)
    Next i_
    
    '
    ' Update information and Hessian.
    ' Check stopping conditions.
    '
    State.RepNFEV = State.RepNFEV + State.NFEV
    State.RepIterationsCount = State.RepIterationsCount + 1#
    If State.RepIterationsCount >= State.MaxIts And State.MaxIts > 0# Then
        
        '
        ' Too many iterations
        '
        State.RepTerminationType = 5#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.G(i_) * State.G(i_)
    Next i_
    If Sqr(V) <= State.EpsG Then
        
        '
        ' Gradient is small enough
        '
        State.RepTerminationType = 4#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    If State.Fold - State.F <= State.EpsF * MaxReal(Abs(State.Fold), MaxReal(Abs(State.F), 1#)) Then
        
        '
        ' F(k+1)-F(k) is small enough
        '
        State.RepTerminationType = 1#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.D(i_) * State.D(i_)
    Next i_
    If Sqr(V) * State.Stp <= State.EpsX Then
        
        '
        ' X(k+1)-X(k) is small enough
        '
        State.RepTerminationType = 2#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    
    '
    ' Shift Xk/Dk, update other information
    '
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.XN(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DK(i_) = State.DN(i_)
    Next i_
    State.Fold = State.F
    State.K = State.K + 1#
    GoTo lbl_6
lbl_7:
    Result = False
    MinCGIteration = Result
    Exit Function
    
    '
    ' Saving state
    '
lbl_rcomm:
    Result = True
    State.RState.IA(0#) = N
    State.RState.IA(1#) = i
    State.RState.IA(2#) = MCINFO
    State.RState.RA(0#) = BetaK
    State.RState.RA(1#) = V
    State.RState.RA(2#) = VV
    MinCGIteration = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Conjugate gradient results
'
'Called after MinCG returned False.
'
'INPUT PARAMETERS:
'    State   -   algorithm state (used by MinCGIteration).
'
'OUTPUT PARAMETERS:
'    X       -   array[0..N-1], solution
'    Rep     -   optimization report:
'                * Rep.TerminationType completetion code:
'                    * -2    rounding errors prevent further improvement.
'                            X contains best point found.
'                    * -1    incorrect parameters were specified
'                    *  1    relative function improvement is no more than
'                            EpsF.
'                    *  2    relative step is no more than EpsX.
'                    *  4    gradient norm is no more than EpsG
'                    *  5    MaxIts steps was taken
'                    *  7    stopping conditions are too stringent,
'                            further improvement is impossible
'                * Rep.IterationsCount contains iterations count
'                * NFEV countains number of function calculations
'
'  -- ALGLIB --
'     Copyright 20.04.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGResults(ByRef State As MinCGState, _
         ByRef X() As Double, _
         ByRef Rep As MinCGReport)
    Dim i_ As Long
    ReDim X(0# To State.N - 1#)
    For i_ = 0# To State.N - 1# Step 1
        X(i_) = State.XN(i_)
    Next i_
    Rep.IterationsCount = State.RepIterationsCount
    Rep.NFEV = State.RepNFEV
    Rep.TerminationType = State.RepTerminationType
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Clears request fileds (to be sure that we don't forgot to clear something)
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Sub ClearRequestFields(ByRef State As MinCGState)
    State.NeedFG = False
    State.XUpdated = False
End Sub

