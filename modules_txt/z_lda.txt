''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Copyright (c) 2008, Sergey Bochkanov (ALGLIB project).
'
'>>> SOURCE LICENSE >>>
'This program is free software; you can redistribute it and/or modify
'it under the terms of the GNU General Public License as published by
'the Free Software Foundation (www.fsf.org); either version 2 of the
'License, or (at your option) any later version.
'
'This program is distributed in the hope that it will be useful,
'but WITHOUT ANY WARRANTY; without even the implied warranty of
'MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
'GNU General Public License for more details.
'
'A copy of the GNU General Public License is available at
'http://www.fsf.org/licensing/licenses
'
'>>> END OF LICENSE >>>
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Routines
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Multiclass Fisher LDA
'
'Subroutine finds coefficients of linear combination which optimally separates
'training set on classes.
'
'INPUT PARAMETERS:
'    XY          -   training set, array[0..NPoints-1,0..NVars].
'                    First NVars columns store values of independent
'                    variables, next column stores number of class (from 0
'                    to NClasses-1) which dataset element belongs to. Fractional
'                    values are rounded to nearest integer.
'    NPoints     -   training set size, NPoints>=0
'    NVars       -   number of independent variables, NVars>=1
'    NClasses    -   number of classes, NClasses>=2
'
'
'OUTPUT PARAMETERS:
'    Info        -   return code:
'                    * -4, if internal EVD subroutine hasn't converged
'                    * -2, if there is a point with class number
'                          outside of [0..NClasses-1].
'                    * -1, if incorrect parameters was passed (NPoints<0,
'                          NVars<1, NClasses<2)
'                    *  1, if task has been solved
'                    *  2, if there was a multicollinearity in training set,
'                          but task has been solved.
'    W           -   linear combination coefficients, array[0..NVars-1]
'
'  -- ALGLIB --
'     Copyright 31.05.2008 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub FisherLDA(ByRef XY() As Double, _
         ByVal NPoints As Long, _
         ByVal NVars As Long, _
         ByVal NClasses As Long, _
         ByRef Info As Long, _
         ByRef w() As Double)
    Dim W2() As Double
    Dim i_ As Long
    Call FisherLDAN(XY, NPoints, NVars, NClasses, Info, W2)
    If Info > 0# Then
        ReDim w(0# To NVars - 1#)
        For i_ = 0# To NVars - 1# Step 1
            w(i_) = W2(i_, 0#)
        Next i_
    End If
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'N-dimensional multiclass Fisher LDA
'
'Subroutine finds coefficients of linear combinations which optimally separates
'training set on classes. It returns N-dimensional basis whose vector are sorted
'by quality of training set separation (in descending order).
'
'INPUT PARAMETERS:
'    XY          -   training set, array[0..NPoints-1,0..NVars].
'                    First NVars columns store values of independent
'                    variables, next column stores number of class (from 0
'                    to NClasses-1) which dataset element belongs to. Fractional
'                    values are rounded to nearest integer.
'    NPoints     -   training set size, NPoints>=0
'    NVars       -   number of independent variables, NVars>=1
'    NClasses    -   number of classes, NClasses>=2
'
'
'OUTPUT PARAMETERS:
'    Info        -   return code:
'                    * -4, if internal EVD subroutine hasn't converged
'                    * -2, if there is a point with class number
'                          outside of [0..NClasses-1].
'                    * -1, if incorrect parameters was passed (NPoints<0,
'                          NVars<1, NClasses<2)
'                    *  1, if task has been solved
'                    *  2, if there was a multicollinearity in training set,
'                          but task has been solved.
'    W           -   basis, array[0..NVars-1,0..NVars-1]
'                    columns of matrix stores basis vectors, sorted by
'                    quality of training set separation (in descending order)
'
'  -- ALGLIB --
'     Copyright 31.05.2008 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub FisherLDAN(ByRef XY() As Double, _
         ByVal NPoints As Long, _
         ByVal NVars As Long, _
         ByVal NClasses As Long, _
         ByRef Info As Long, _
         ByRef w() As Double)
    Dim i As Long
    Dim j As Long
    Dim K As Long
    Dim M As Long
    Dim V As Double
    Dim C() As Long
    Dim Mu() As Double
    Dim MuC() As Double
    Dim NC() As Long
    Dim SW() As Double
    Dim ST() As Double
    Dim z() As Double
    Dim Z2() As Double
    Dim TM() As Double
    Dim SBRoot() As Double
    Dim A() As Double
    Dim XYProj() As Double
    Dim WProj() As Double
    Dim TF() As Double
    Dim D() As Double
    Dim D2() As Double
    Dim WORK() As Double
    Dim i_ As Long
    
    '
    ' Test data
    '
    If NPoints < 0# Or NVars < 1# Or NClasses < 2# Then
        Info = -1#
        Exit Sub
    End If
    For i = 0# To NPoints - 1# Step 1
        If Round(XY(i, NVars)) < 0# Or Round(XY(i, NVars)) >= NClasses Then
            Info = -2#
            Exit Sub
        End If
    Next i
    Info = 1#
    
    '
    ' Special case: NPoints<=1
    ' Degenerate task.
    '
    If NPoints <= 1# Then
        Info = 2#
        ReDim w(0# To NVars - 1#, 0# To NVars - 1#)
        For i = 0# To NVars - 1# Step 1
            For j = 0# To NVars - 1# Step 1
                If i = j Then
                    w(i, j) = 1#
                Else
                    w(i, j) = 0#
                End If
            Next j
        Next i
        Exit Sub
    End If
    
    '
    ' Prepare temporaries
    '
    ReDim TF(0# To NVars - 1#)
    ReDim WORK(1# To MaxInt(NVars, NPoints))
    
    '
    ' Convert class labels from reals to integers (just for convenience)
    '
    ReDim C(0# To NPoints - 1#)
    For i = 0# To NPoints - 1# Step 1
        C(i) = Round(XY(i, NVars))
    Next i
    
    '
    ' Calculate class sizes and means
    '
    ReDim Mu(0# To NVars - 1#)
    ReDim MuC(0# To NClasses - 1#, 0# To NVars - 1#)
    ReDim NC(0# To NClasses - 1#)
    For j = 0# To NVars - 1# Step 1
        Mu(j) = 0#
    Next j
    For i = 0# To NClasses - 1# Step 1
        NC(i) = 0#
        For j = 0# To NVars - 1# Step 1
            MuC(i, j) = 0#
        Next j
    Next i
    For i = 0# To NPoints - 1# Step 1
        For i_ = 0# To NVars - 1# Step 1
            Mu(i_) = Mu(i_) + XY(i, i_)
        Next i_
        For i_ = 0# To NVars - 1# Step 1
            MuC(C(i), i_) = MuC(C(i), i_) + XY(i, i_)
        Next i_
        NC(C(i)) = NC(C(i)) + 1#
    Next i
    For i = 0# To NClasses - 1# Step 1
        V = 1# / NC(i)
        For i_ = 0# To NVars - 1# Step 1
            MuC(i, i_) = V * MuC(i, i_)
        Next i_
    Next i
    V = 1# / NPoints
    For i_ = 0# To NVars - 1# Step 1
        Mu(i_) = V * Mu(i_)
    Next i_
    
    '
    ' Create ST matrix
    '
    ReDim ST(0# To NVars - 1#, 0# To NVars - 1#)
    For i = 0# To NVars - 1# Step 1
        For j = 0# To NVars - 1# Step 1
            ST(i, j) = 0#
        Next j
    Next i
    For K = 0# To NPoints - 1# Step 1
        For i_ = 0# To NVars - 1# Step 1
            TF(i_) = XY(K, i_)
        Next i_
        For i_ = 0# To NVars - 1# Step 1
            TF(i_) = TF(i_) - Mu(i_)
        Next i_
        For i = 0# To NVars - 1# Step 1
            V = TF(i)
            For i_ = 0# To NVars - 1# Step 1
                ST(i, i_) = ST(i, i_) + V * TF(i_)
            Next i_
        Next i
    Next K
    
    '
    ' Create SW matrix
    '
    ReDim SW(0# To NVars - 1#, 0# To NVars - 1#)
    For i = 0# To NVars - 1# Step 1
        For j = 0# To NVars - 1# Step 1
            SW(i, j) = 0#
        Next j
    Next i
    For K = 0# To NPoints - 1# Step 1
        For i_ = 0# To NVars - 1# Step 1
            TF(i_) = XY(K, i_)
        Next i_
        For i_ = 0# To NVars - 1# Step 1
            TF(i_) = TF(i_) - MuC(C(K), i_)
        Next i_
        For i = 0# To NVars - 1# Step 1
            V = TF(i)
            For i_ = 0# To NVars - 1# Step 1
                SW(i, i_) = SW(i, i_) + V * TF(i_)
            Next i_
        Next i
    Next K
    
    '
    ' Maximize ratio J=(w'*ST*w)/(w'*SW*w).
    '
    ' First, make transition from w to v such that w'*ST*w becomes v'*v:
    '    v  = root(ST)*w = R*w
    '    R  = root(D)*Z'
    '    w  = (root(ST)^-1)*v = RI*v
    '    RI = Z*inv(root(D))
    '    J  = (v'*v)/(v'*(RI'*SW*RI)*v)
    '    ST = Z*D*Z'
    '
    '    so we have
    '
    '    J = (v'*v) / (v'*(inv(root(D))*Z'*SW*Z*inv(root(D)))*v)  =
    '      = (v'*v) / (v'*A*v)
    '
    If Not SMatrixEVD(ST, NVars, 1#, True, D, z) Then
        Info = -4#
        Exit Sub
    End If
    ReDim w(0# To NVars - 1#, 0# To NVars - 1#)
    If D(NVars - 1#) <= 0# Or D(0#) <= 1000# * MachineEpsilon * D(NVars - 1#) Then
        
        '
        ' Special case: D[NVars-1]<=0
        ' Degenerate task (all variables takes the same value).
        '
        If D(NVars - 1#) <= 0# Then
            Info = 2#
            For i = 0# To NVars - 1# Step 1
                For j = 0# To NVars - 1# Step 1
                    If i = j Then
                        w(i, j) = 1#
                    Else
                        w(i, j) = 0#
                    End If
                Next j
            Next i
            Exit Sub
        End If
        
        '
        ' Special case: degenerate ST matrix, multicollinearity found.
        ' Since we know ST eigenvalues/vectors we can translate task to
        ' non-degenerate form.
        '
        ' Let WG is orthogonal basis of the non zero variance subspace
        ' of the ST and let WZ is orthogonal basis of the zero variance
        ' subspace.
        '
        ' Projection on WG allows us to use LDA on reduced M-dimensional
        ' subspace, N-M vectors of WZ allows us to update reduced LDA
        ' factors to full N-dimensional subspace.
        '
        M = 0#
        For K = 0# To NVars - 1# Step 1
            If D(K) <= 1000# * MachineEpsilon * D(NVars - 1#) Then
                M = K + 1#
            End If
        Next K
        ReDim XYProj(0# To NPoints - 1#, 0# To NVars - M)
        Call MatrixMatrixMultiply(XY, 0#, NPoints - 1#, 0#, NVars - 1#, False, z, 0#, NVars - 1#, M, NVars - 1#, False, 1#, XYProj, 0#, NPoints - 1#, 0#, NVars - M - 1#, 0#, WORK)
        For i = 0# To NPoints - 1# Step 1
            XYProj(i, NVars - M) = XY(i, NVars)
        Next i
        Call FisherLDAN(XYProj, NPoints, NVars - M, NClasses, Info, WProj)
        If Info < 0# Then
            Exit Sub
        End If
        Call MatrixMatrixMultiply(z, 0#, NVars - 1#, M, NVars - 1#, False, WProj, 0#, NVars - M - 1#, 0#, NVars - M - 1#, False, 1#, w, 0#, NVars - 1#, 0#, NVars - M - 1#, 0#, WORK)
        For K = NVars - M To NVars - 1# Step 1
            For i_ = 0# To NVars - 1# Step 1
                w(i_, K) = z(i_, K - (NVars - M))
            Next i_
        Next K
        Info = 2#
    Else
        
        '
        ' General case: no multicollinearity
        '
        ReDim TM(0# To NVars - 1#, 0# To NVars - 1#)
        ReDim A(0# To NVars - 1#, 0# To NVars - 1#)
        Call MatrixMatrixMultiply(SW, 0#, NVars - 1#, 0#, NVars - 1#, False, z, 0#, NVars - 1#, 0#, NVars - 1#, False, 1#, TM, 0#, NVars - 1#, 0#, NVars - 1#, 0#, WORK)
        Call MatrixMatrixMultiply(z, 0#, NVars - 1#, 0#, NVars - 1#, True, TM, 0#, NVars - 1#, 0#, NVars - 1#, False, 1#, A, 0#, NVars - 1#, 0#, NVars - 1#, 0#, WORK)
        For i = 0# To NVars - 1# Step 1
            For j = 0# To NVars - 1# Step 1
                A(i, j) = A(i, j) / Sqr(D(i) * D(j))
            Next j
        Next i
        If Not SMatrixEVD(A, NVars, 1#, True, D2, Z2) Then
            Info = -4#
            Exit Sub
        End If
        For K = 0# To NVars - 1# Step 1
            For i = 0# To NVars - 1# Step 1
                TF(i) = Z2(i, K) / Sqr(D(i))
            Next i
            For i = 0# To NVars - 1# Step 1
                V = 0#
                For i_ = 0# To NVars - 1# Step 1
                    V = V + z(i, i_) * TF(i_)
                Next i_
                w(i, K) = V
            Next i
        Next K
    End If
    
    '
    ' Post-processing:
    ' * normalization
    ' * converting to non-negative form, if possible
    '
    For K = 0# To NVars - 1# Step 1
        V = 0#
        For i_ = 0# To NVars - 1# Step 1
            V = V + w(i_, K) * w(i_, K)
        Next i_
        V = 1# / Sqr(V)
        For i_ = 0# To NVars - 1# Step 1
            w(i_, K) = V * w(i_, K)
        Next i_
        V = 0#
        For i = 0# To NVars - 1# Step 1
            V = V + w(i, K)
        Next i
        If V < 0# Then
            For i_ = 0# To NVars - 1# Step 1
                w(i_, K) = -1 * w(i_, K)
            Next i_
        End If
    Next K
End Sub

